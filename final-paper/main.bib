@misc{qwen_2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen-Team},
    month = {9},
    year = {2024}
}

@misc{transformers,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.03771},
}

@misc{neftune,
      title={NEFTune: Noisy Embeddings Improve Instruction Finetuning},
      author={Neel Jain and Ping-yeh Chiang and Yuxin Wen and John Kirchenbauer and Hong-Min Chu and Gowthami Somepalli and Brian R. Bartoldson and Bhavya Kailkhura and Avi Schwarzschild and Aniruddha Saha and Micah Goldblum and Jonas Geiping and Tom Goldstein},
      year={2023},
      eprint={2310.05914},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.05914},
}

@misc{dpo,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290},
}

@misc{qlora,
      title={QLoRA: Efficient Finetuning of Quantized LLMs},
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314},
}

@misc{flash_attention,
      title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning},
      author={Tri Dao},
      year={2023},
      eprint={2307.08691},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.08691},
}

@misc{huggingface_leaderboard,
	author = {Clementine Fourrier and Nathan Habib and Alina Lozovskaya and Konrad Szafer and Thomas Wolf},
	title = {Open LLM Leaderboard 2},
	url = {https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard},
	year = {2024},
}

@misc{cornell_movie_data,
	author = {Rajath Chidananda},
	title = {Cornell Movie-Dialog Corpus},
	url = {https://www.kaggle.com/datasets/rajathmc/cornell-moviedialog-corpus},
	year = {2018},
}

@misc{packing,
	author = {Lukas Hauzenberger},
	title = {Efficient LLM Pretraining: Packed Sequences and Masked Attention},
	url = {https://huggingface.co/blog/sirluk/llm-sequence-packing},
	year = {2024},
}

@misc{gradient_accumulation,
	author = {Raz Rotenberg},
	title = {What is Gradient Accumulation in Deep Learning?},
	url = {https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa},
	year = {2020},
}
